{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "### Saving LinkedIn's Profile Data into Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "def get_linkedin_data(extracted_linkedin_url, metadata):\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Enables headless mode\n",
    "\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "    try:\n",
    "        driver.get(extracted_linkedin_url)\n",
    "        html_content = driver.page_source\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    title = soup.title.string if soup.title else \"Title not found\"\n",
    "\n",
    "    # Find all <script type=\"application/ld+json\"> tags and extract the JSON from the first one\n",
    "    script_tags = soup.find_all('script', type=\"application/ld+json\")\n",
    "    json_str = script_tags[0].text  # Use .text or .string to get the content of the tag\n",
    "    data = json.loads(json_str)  # Parse the JSON string\n",
    "    \n",
    "    # Initialize an empty string to accumulate the extracted data\n",
    "    extracted_data = \"\"\n",
    "\n",
    "    extracted_data += f\"Title: {title}\\n\\n\"\n",
    "\n",
    "    # Extract the meta description content\n",
    "    meta_description = soup.find('meta', {'name': 'description'})['content'] if soup.find('meta', {'name': 'description'}) else \"Description not found\"\n",
    "    extracted_data += f\"- Description: {meta_description}\\n\"\n",
    "\n",
    "    # Assuming the person's info is the first entry in the \"@graph\" list\n",
    "    person_info = data[\"@graph\"][0]\n",
    "\n",
    "    name = person_info.get(\"name\", \"\")\n",
    "    extracted_data += f\"Name: {name}\\n\\n\"\n",
    "\n",
    "    # Extracting alumni and work information\n",
    "    extracted_data += \"Work Experience:\\n\"\n",
    "    alumni_of = person_info.get(\"alumniOf\", [])\n",
    "    for alumni in alumni_of:\n",
    "        org_name = alumni.get(\"name\", \"\")\n",
    "        member = alumni.get(\"member\", {})\n",
    "        role = member.get(\"description\", \"\")  # Access description\n",
    "        extracted_data += f\"- Organization: {org_name}, Role: {role}\\n\\n\"\n",
    "\n",
    "    member_of = person_info.get(\"memberOf\", [])\n",
    "    for member in member_of:\n",
    "        org_name = member.get(\"name\", \"\")\n",
    "        role = member.get(\"description\", \"\")\n",
    "        extracted_data += f\"- Organization: {org_name}, Role: {role}\\n\\n\"\n",
    "\n",
    "    # Extracting languages\n",
    "    extracted_data += \"\\nLanguages Known:\\n\"\n",
    "    languages = person_info.get(\"knowsLanguage\", [])\n",
    "    for language in languages:\n",
    "        language_name = language.get(\"name\", \"\")\n",
    "        extracted_data += f\"- {language_name}\\n\"\n",
    "    \n",
    "    file_name = f\"{metadata['first_name']}_{metadata['last_name']}.txt\"\n",
    "    with open(file_name, \"w\") as file:\n",
    "        file.write(extracted_data)\n",
    "        \n",
    "    return extracted_data"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
